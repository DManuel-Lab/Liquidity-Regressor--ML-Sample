{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fc3f2b",
   "metadata": {},
   "source": [
    "# Liquidity Regressor Machine Learning Initial Framework\n",
    "A framework for predicting the optimal level of liquidity for a company. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3557b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import initially needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27915196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as NP\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9641b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import my preferred ML library Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3680ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c61465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Sample Data CSV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b96235",
   "metadata": {},
   "source": [
    "liquidity_data = pd.read_csv('Sample Data in GitHub Repo') # Markdown Cell. Must change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba87d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Engineering Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "liquidity_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new DataFrames named \"inputs\" containing only the input features and \"test\" for test features\n",
    "target = liquidity_data.available_liquidity\n",
    "\n",
    "inputs = liquidity_data.drop('available_liquidity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee267bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data and pass the results to a new object named \"results\"\n",
    "results = train_test_split(inputs, target, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data integrity check to ensure the total rows matches from our summary statistics and data is divided properly\n",
    "print(type(results))\n",
    "print(len(results))\n",
    "print('--%--')\n",
    "for item in results:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b7c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for ingestion for our chosen model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc40502",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, input_test, target_train, target_test = results\n",
    "print(input_train.shape)\n",
    "print(input_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)\n",
    "# confirm the shape of each new variable ready for testing is the same as our prior check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbba98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required functions from Scikit-Learn\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create pipelines in a dictionary with model pipelines for Lasso and Ridge\n",
    "\n",
    "pipelines = {\n",
    "    'lasso' : make_pipeline(StandardScaler(), Lasso(random_state=1)),\n",
    "    'ridge' : make_pipeline(StandardScaler(), Ridge(random_state=1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c968283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new pipeline to the pipeline dictionary\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "pipelines['enet'] = make_pipeline(StandardScaler(), ElasticNet(random_state=1))\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "pipelines['rf'] = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=1))\n",
    "pipelines['gb'] = make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97900122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress check\n",
    "# Ensure pipelines are set up correctly \n",
    "for key, value in pipelines.items():\n",
    "    print(key, type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7d1eb",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e483bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hyperparameter grid for Lasso\n",
    "lasso_hyperparameters = {\n",
    "    'lasso__alpha' : [0.01,0.05,0.1,0.5,1,5]\n",
    "    # the model class name followed by 2 underscores then the hp name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hyperparameter grid for Ridge\n",
    "ridge_hyperparameters = {\n",
    "    'ridge__alpha' : [0.01,0.05,0.1,0.5,1,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b02470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hyperparameter grid for Elastic Net\n",
    "enet_hyperparameters = {\n",
    "    'elasticnet__alpha' : [0.01, 0.05, 0.1, 0.5, 1, 5],\n",
    "    'elasticnet__l1_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hyperparameter grid for Random Forest\n",
    "rf_hyperparameters = {\n",
    "    'randomforestregressor__n_estimators' : [100,200], # n estimators is the number of decision trees\n",
    "    'randomforestregressor__max_features' : ['auto', 0.3, 0.6] # tells the model how many features it's allowed to use to prevent overfitting\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e92a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hyperparameter grid for Gradient Booster\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingregressor__n_estimators' : [100, 200],\n",
    "    'gradientboostingregressor__learning_rate' : [0.05, 0.1, 0.2],\n",
    "    'gradientboostingregressor__max_depth' : [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5063e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hyperparameter_grids dictionary\n",
    "hyperparameter_grids = {\n",
    "    'lasso' : lasso_hyperparameters,\n",
    "    'ridge' : ridge_hyperparameters,\n",
    "    'enet' : enet_hyperparameters,\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2238de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code below to make sure everything is set up correctly\n",
    "for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "    if key in hyperparameter_grids:\n",
    "        if type(hyperparameter_grids[key]) is dict:\n",
    "            print( key, 'was found, and it is a grid.' )\n",
    "        else:\n",
    "            print( key, 'was found, but it is not a grid.' )\n",
    "    else:\n",
    "        print( key, 'was not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c886e8",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89cc38a",
   "metadata": {},
   "source": [
    "#### Creating Untrained ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f68cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_lasso_model = GridSearchCV(pipelines['lasso'], hyperparameter_grids['lasso'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd864a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in pipelines.keys():\n",
    "         models[key] = GridSearchCV(pipelines[key],hyperparameter_grids[key], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a078e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.keys() # to check models dictionary has been labeled correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d402cc",
   "metadata": {},
   "source": [
    "## Training & Tuning the Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5230609",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models.keys():\n",
    "    models[key].fit(input_train,target_train)\n",
    "    print(key,'is trained and tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8def80d",
   "metadata": {},
   "source": [
    "## Select A Winning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the r-squared and mean absolute error metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare test predictions agains actual target variable values\n",
    "preds = {}\n",
    "\n",
    "for key in models: \n",
    "    preds = models[key].predict(input_test)\n",
    "    print(key)\n",
    "    print('R-Squared:', round(r2_score(target_test,preds), 3))\n",
    "    print('MAE:', round(mean_absolute_error(target_test,preds), 3))\n",
    "    print('---Divider---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Gradient Booster Should be the winning model from the sample data *** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37412285",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = models['gb'].predict(input_test)\n",
    "plt.scatter(preds, target_test)\n",
    "\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In using the model to advise clients,\n",
    "#  pass the model a dataframe in the same format as the training, \n",
    "#   but without the column containing the target variable, and one line with client data. \n",
    "#    Then, pass the dataframe to the trained model to calculate the model's prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
